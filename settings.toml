env_file = "environment/Tennis.app"
seed = 24
cores = 4

[PPO]
epochs_mean_rewards = 100 # Number of epochs to compute mean rewards

[ActorCritic]
layers = 3
activation = "tanh"
hidden_nodes = 64
policy_lr = 3e-4
value_lr = 1e-3
train_policy_iters = 80
train_value_iters = 80